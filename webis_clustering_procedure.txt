# create
create_webis_miniclusters.py (run_miniclusters.sh)
-> create clusters and dumps them to ./data/webis/clusters/umap_(....)_cluster_.. (one file per cluster; total 1088 files)
-> preliminary evaluation to ./viz_reults/webis_miniclusters_merge_80k/results/umap**pkl (one file per clustering method, i.e. <= 10 clusters; total 120 files)
(old: .._merge_80k_OLD_BACKUP)

# eval
evaluate_webis_clusters.py (run_eval_webis_clsuter.sh) 
evaluate those clusters and save the results to

./aggregated_clustering_results (transfer this to pc)
./clustering_results (I think we don't need this)
(one file per cluster, 1088 files)

# select
select_representative_clusters load those files from eval (aggregated_clustering_results/*.pkl)

saves the selection to
"./data/webis/selected_clusters_indices_to_path.json" (index -> path cluster dataset)
(old: "./data/webis/cluster_index_to_path.json")

and draws to "viz_results/webis_selected_clusters" (before viz_results/webis_many_clusters_old_backup)

# iterative train
loads from: "./data/webis/selected_clusters_indices_to_path.json"
save u webis_clusters_results_v2



TODO: promojeni path u 	correlate_metrics.py;plot_collapse.py;regression_analysis.py





